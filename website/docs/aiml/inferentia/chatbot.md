---
title: "Run Chatbot using AWS Inferentia, Ray Serve, Gradio on Amazon EKS"
sidebar_position: 30
---

Welcome to the comprehensive guide on deploying the Meta Llama-2-13b chat model on Amazon Elastic Kubernetes Service (EKS) using Ray Serve. In this section, you will not only learn how to harness the power of Llama-2, but also gain insights into the intricacies of deploying large language models (LLMs) efficiently, particularly on inf2 (powered by AWS Inferentia) instances, such as inf2.24xlarge and inf2.48xlarge, which are optimized for deploying and scaling large language models.

## TODO @natmhnty
